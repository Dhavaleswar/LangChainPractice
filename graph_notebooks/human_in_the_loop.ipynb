{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Lesson 5: Human in the Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.helpers import set_api_keys_env\n",
    "set_api_keys_env()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, END\n",
    "from typing import TypedDict, Annotated\n",
    "import operator\n",
    "from langchain_core.messages import AnyMessage, SystemMessage, HumanMessage, ToolMessage, AIMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langgraph.checkpoint.sqlite import SqliteSaver\n",
    "from uuid import uuid4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\"\"\"\n",
    "In previous examples we've annotated the `messages` state key\n",
    "with the default `operator.add` or `+` reducer, which always\n",
    "appends new messages to the end of the existing messages array.\n",
    "\n",
    "Now, to support replacing existing messages, we annotate the\n",
    "`messages` key with a customer reducer function, which replaces\n",
    "messages with the same `id`, and appends them otherwise.\n",
    "\"\"\"\n",
    "def reduce_messages(left: list[AnyMessage], right: list[AnyMessage]) -> list[AnyMessage]:\n",
    "    # assign ids to messages that don't have them\n",
    "    for message in right:\n",
    "        if not message.id:\n",
    "            message.id = str(uuid4())\n",
    "    # merge the new messages with the existing messages\n",
    "    merged = left.copy()\n",
    "    for message in right:\n",
    "        for i, existing in enumerate(merged):\n",
    "            # replace any existing messages with the same id\n",
    "            if existing.id == message.id:\n",
    "                merged[i] = message\n",
    "                break\n",
    "        else:\n",
    "            # append any new messages to the end\n",
    "            merged.append(message)\n",
    "    return merged\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    messages: Annotated[list[AnyMessage], reduce_messages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    def __init__(self, model, tools, system=\"\", checkpointer=None):\n",
    "        self.system = system\n",
    "        graph = StateGraph(AgentState)\n",
    "        graph.add_node(\"llm\", self.call_openai)\n",
    "        graph.add_node(\"action\", self.take_action)\n",
    "        graph.add_conditional_edges(\"llm\", self.exists_action, {True: \"action\", False: END})\n",
    "        graph.add_edge(\"action\", \"llm\")\n",
    "        graph.set_entry_point(\"llm\")\n",
    "        self.graph = graph.compile(\n",
    "            checkpointer=checkpointer,\n",
    "            interrupt_before=[\"action\"]\n",
    "        )\n",
    "        self.tools = {t.name: t for t in tools}\n",
    "        self.model = model.bind_tools(tools)\n",
    "\n",
    "    def call_openai(self, state: AgentState):\n",
    "        messages = state['messages']\n",
    "        if self.system:\n",
    "            messages = [SystemMessage(content=self.system)] + messages\n",
    "        message = self.model.invoke(messages)\n",
    "        return {'messages': [message]}\n",
    "\n",
    "    def exists_action(self, state: AgentState):\n",
    "        print(state)\n",
    "        result = state['messages'][-1]\n",
    "        return len(result.tool_calls) > 0\n",
    "\n",
    "    def take_action(self, state: AgentState):\n",
    "        tool_calls = state['messages'][-1].tool_calls\n",
    "        results = []\n",
    "        for t in tool_calls:\n",
    "            print(f\"Calling: {t}\")\n",
    "            result = self.tools[t['name']].invoke(t['args'])\n",
    "            results.append(ToolMessage(tool_call_id=t['id'], name=t['name'], content=str(result)))\n",
    "        print(\"Back to the model!\")\n",
    "        return {'messages': results}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tool = TavilySearchResults(max_results=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"You are a smart research assistant. Use the search engine to look up information. \\\n",
    "You are allowed to make multiple calls (either together or in sequence). \\\n",
    "Only look up information when you are sure of what you want. \\\n",
    "If you need to look up some information before asking a follow up question, you are allowed to do that!\n",
    "\"\"\"\n",
    "model = ChatOpenAI(model=\"gpt-4o\")\n",
    "thread1 = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "thread2 = {\"configurable\": {\"thread_id\": \"2\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with SqliteSaver.from_conn_string(\":memory:\") as mem:\n",
    "    abot = Agent(model, [tool], system=prompt, checkpointer=mem)\n",
    "    messages = [HumanMessage(content=\"Whats the weather in Banglore?\")]\n",
    "    for event in abot.graph.stream({'messages': messages}, thread1):\n",
    "        for v in event.values():\n",
    "            print(v)\n",
    "            print(\"-------------------------------------------------------------\")\n",
    "    print(\"Info Current State -------------------------------------------------------------\")\n",
    "    curr_state = abot.graph.get_state(thread1)\n",
    "    print(\"Current state:\", curr_state)\n",
    "    print(\"Next State: \", curr_state.next)\n",
    "    print(\"Continue after Interrupt -------------------------------------------------------------\")\n",
    "    for event in abot.graph.stream(None, thread1):\n",
    "        for v in event.values():\n",
    "            print(v)\n",
    "            print(\"-------------------------------------------------------------\")\n",
    "    curr_state = abot.graph.get_state(thread1)\n",
    "    print(\"Current state:\", curr_state)\n",
    "    print(\"Next State: \", curr_state.next)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "with SqliteSaver.from_conn_string(\":memory:\") as mem:\n",
    "    abot = Agent(model, [tool], system=prompt, checkpointer=mem)\n",
    "    messages = [HumanMessage(content=\"Whats the weather in Banglore?\")]\n",
    "    for event in abot.graph.stream({\"messages\": messages}, thread2):\n",
    "        for v in event.values():\n",
    "            print(v)\n",
    "            print(\"-------------------------------------------------------------\")\n",
    "    print(\"Info Current State -------------------------------------------------------------\")\n",
    "    curr_state = abot.graph.get_state(thread2)\n",
    "    print(\"Current state:\", curr_state)\n",
    "    print(\"Next State: \", curr_state.next)\n",
    "    print(\"Continue after Interrupt -------------------------------------------------------------\")\n",
    "    while abot.graph.get_state(thread2).next:\n",
    "        print(\"Current State: \\n\", abot.graph.get_state(thread2),\"\\n\")\n",
    "        _input = input(\"proceed?\")\n",
    "        if _input != \"y\":\n",
    "            print(\"aborting\")\n",
    "            break\n",
    "        for event in abot.graph.stream(None, thread2):\n",
    "            for v in event.values():\n",
    "                print(v)\n",
    "                print(\"-------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "### Updating State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mem1 = SqliteSaver.from_conn_string(\":memory:\")\n",
    "messages = [HumanMessage(content=\"Whats the weather in Chembakur, Andhra Pradesh?\")]\n",
    "thread3 = {\"configurable\": {\"thread_id\": \"3\"}}\n",
    "with SqliteSaver.from_conn_string(\":memory:\") as mem1:\n",
    "    abot = Agent(model, [tool], system=prompt, checkpointer=mem1)\n",
    "    for event in abot.graph.stream({\"messages\": messages}, thread3):\n",
    "        for v in event.values():\n",
    "            print(v)\n",
    "            print(\"-------------------------------------------------------------\")\n",
    "\n",
    "    print(\"Info Current State -------------------------------------------------------------\")\n",
    "    curr_state = abot.graph.get_state(thread3)\n",
    "    print(\"Current state:\", curr_state)\n",
    "\n",
    "    last_message = curr_state.values['messages'][-1]\n",
    "    print(\"Last message:\", last_message)\n",
    "    print(\"Tool Calls:\", last_message.tool_calls)\n",
    "\n",
    "    tool_ = last_message.tool_calls[0]\n",
    "    tool_id = tool_['id']\n",
    "    curr_state.values['messages'][-1].tool_calls = [{\n",
    "        'name': tool.name,\n",
    "        'args': {'query': 'weather in MadanaPalle, Andhra Pradesh'},\n",
    "        'id': tool_id,\n",
    "    }]\n",
    "    print(f\"before update: {abot.graph.get_state(thread3)}\")\n",
    "\n",
    "    abot.graph.update_state(thread3, curr_state.values)\n",
    "\n",
    "    print(f\"after update: {abot.graph.get_state(thread3)}\")\n",
    "    ### Run the graph after update\n",
    "    print(f\"CUrrent State after update\")\n",
    "    curr_state = abot.graph.get_state(thread3)\n",
    "    print(\"Current state:\", curr_state)\n",
    "    print(\"Next State: \", curr_state.next)\n",
    "    print(\"Continue after Interrupt -------------------------------------------------------------\")\n",
    "\n",
    "    for event in abot.graph.stream(None, thread3):\n",
    "        for v in event.values():\n",
    "            print(v)\n",
    "            print(\"-------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.memory import InMemorySaver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [HumanMessage(content=\"Whats the weather in Chembakur, Andhra Pradesh?\")]\n",
    "thread3 = {\"configurable\": {\"thread_id\": \"3\"}}\n",
    "inmem = InMemorySaver()\n",
    "abot = Agent(model, [tool], system=prompt, checkpointer=inmem)\n",
    "for event in abot.graph.stream({\"messages\": messages}, thread3):\n",
    "    for v in event.values():\n",
    "        print(v)\n",
    "        print(\"-------------------------------------------------------------\")\n",
    "print(\"===============================================================================================================\")\n",
    "print(\"======================================================== Before Update ========================================\")\n",
    "print(\"===============================================================================================================\")\n",
    "for state in abot.graph.get_state_history(thread3):\n",
    "    print(\"State: \", state)\n",
    "    print(\"messages: \", len(state.values['messages']))\n",
    "    print(\"-------------------------------\")\n",
    "    # break\n",
    "\n",
    "curr_state = abot.graph.get_state(thread3)\n",
    "last_message = curr_state.values['messages'][-1]\n",
    "tool_ = last_message.tool_calls[0]\n",
    "tool_id = tool_['id']\n",
    "curr_state.values['messages'][-1].tool_calls = [{\n",
    "    'name': tool.name,\n",
    "    'args': {'query': 'weather in MadanaPalle, Andhra Pradesh'},\n",
    "    'id': tool_id,\n",
    "}]\n",
    "abot.graph.update_state(thread3, curr_state.values)\n",
    "\n",
    "print(\"===============================================================================================================\")\n",
    "print(\"======================================================== After Update ========================================\")\n",
    "print(\"===============================================================================================================\")\n",
    "states = []\n",
    "for state in abot.graph.get_state_history(thread3):\n",
    "    states.append(state)\n",
    "    print(\"**State: \", state)\n",
    "    print(\"**messages: \", len(state.values['messages']))\n",
    "    print(\"-------------------------------\")\n",
    "    # break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "### Time Travel "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_replay1 = states[0]\n",
    "to_replay2 = states[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_replay1.values['messages'][-1].tool_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_replay2.values['messages'][-1].tool_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "for event in abot.graph.stream(None, to_replay1.config):\n",
    "    for k, v in event.items():\n",
    "        print(f\" Event {k}: {v}\")\n",
    "        print(\"-------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(list(abot.graph.get_state_history(thread3)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_state = abot.graph.get_state(thread3)\n",
    "curr_state.values['messages']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "for event in abot.graph.stream(None, to_replay2.config):\n",
    "    for k, v in event.items():\n",
    "        print(f\" Event {k}: {v}\")\n",
    "        print(\"-------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(list(abot.graph.get_state_history(thread3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_state = abot.graph.get_state(thread3)\n",
    "curr_state.values['messages']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "_id = to_replay1.values['messages'][-1].tool_calls[0]['id']\n",
    "to_replay1.values['messages'][-1].tool_calls = [{\n",
    "    'name': tool.name,\n",
    "    'args': {'query': 'weather in Chintamani, Karnataka'},\n",
    "    'id': _id,\n",
    "}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "branch_state = abot.graph.update_state(to_replay1.config, to_replay1.values)\n",
    "# branch_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "for event in abot.graph.stream(None, branch_state):\n",
    "    for k, v in event.items():\n",
    "        print(f\" Event {k}: {v}\")\n",
    "        print(\"-------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(list(abot.graph.get_state_history(thread3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_state = abot.graph.get_state(thread3)\n",
    "curr_state.values['messages']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "_id = to_replay1.values['messages'][-1].tool_calls[0]['id']\n",
    "state_update = {'messages': [ToolMessage(tool_call_id=_id, name=tool.name, content=\"Weather in Chembakur, Andhra Pradesh is 30C\")]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "branch_and_add = abot.graph.update_state(\n",
    "    to_replay1.config,\n",
    "    state_update,\n",
    "    as_node=\"action\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "for event in abot.graph.stream(None, branch_and_add):\n",
    "    for k, v in event.items():\n",
    "        print(f\" Event {k}: {v}\")\n",
    "        print(\"-------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(list(abot.graph.get_state_history(thread3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_state = abot.graph.get_state(thread3)\n",
    "curr_state.values['messages']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
