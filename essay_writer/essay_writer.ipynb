{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.helpers import set_api_keys_env\n",
    "set_api_keys_env()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "#### Essay Writer Design\n",
    "\n",
    "1. Plan ===> Research Plan\n",
    "2. Research Plan ===> Generate\n",
    "3. Generate\n",
    "    a. if OK: end\n",
    "    b. if not OK\n",
    "        i. Generate ===> Reflect\n",
    "        ii. Reflect ===> Research Critique\n",
    "        iii. Research Critique ===> Generate (3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, END\n",
    "from typing import TypedDict, Annotated, List\n",
    "import operator\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "from langchain_core.messages import AnyMessage, SystemMessage, HumanMessage, ToolMessage\n",
    "from rich.console import Console\n",
    "from rich.markdown import Markdown\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentState(TypedDict):\n",
    "    task: str # This is the human input\n",
    "    plan: str # Key to keep track of plan, planning agent will generate\n",
    "    draft: str # draft of the essay\n",
    "    critique: str # critique of the draft, critique agent\n",
    "    content: List[str] # list of document that tavily has researched\n",
    "    revision_number: int # number of revisions made to the draft\n",
    "    max_revision: int # maximum number of revisions allowed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-4o\", temperature=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "PLAN_PROMPT = \"\"\"You are an expert writer tasked with writing high level outline of an essay. \\\n",
    "Write such an outline for the user provided topic. Give an outline of the essay along with any relevant notes \\\n",
    "    or instructions for the sections. \\\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "RESEARCH_PLAN_PROMPT = \"\"\"You are a researcher charged with providing information that can \\\n",
    "be used when writing the following essay. Generate a list of search queries that will gather \\\n",
    "any relevant information. Only generate 3 queries max.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "WRITER_PROMPT = \"\"\"You are an essay assistant tasked with writing excellent 5-paragraph essays. \\\n",
    "Generate the best essay possible fo rthe user's request and the initial outline. \\\n",
    "If the user provides critique, respond with a revised version of your previous attempts. \\\n",
    "Utilize all the information below as needed:\n",
    "\n",
    "------\n",
    "{content}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "REFLECTION_PROMPT = \"\"\"You are a teacher grading an essay submission. \\\n",
    "Generate critique and recommendations for the user's submission. \\\n",
    "Provide detailed recommendations, including requests for length, depth, style, etc.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "RESEARCH_CRITIQUE_PROMPT = \"\"\"You are a researcher charged with providing information that can \\\n",
    "be used when making any requested revisions (as outlined below). \\\n",
    "Generate a list of search queries that will gather any releavant information. Only generate 3 queries max.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.pydantic_v1 import BaseModel\n",
    "\n",
    "class Queries(BaseModel):\n",
    "    queries: List[str]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tavily import TavilyClient\n",
    "\n",
    "tavily = TavilyClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "#### Nodes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plan_node(state: AgentState):\n",
    "    messages = [\n",
    "        SystemMessage(content=PLAN_PROMPT),\n",
    "        HumanMessage(content=state[\"task\"]),\n",
    "    ]\n",
    "    response = model.invoke(messages)\n",
    "    return {\"plan\": response.content}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def research_plan_node(state:AgentState):\n",
    "    queries = model.with_structured_output(Queries).invoke([\n",
    "        SystemMessage(content=RESEARCH_PLAN_PROMPT),\n",
    "        HumanMessage(content=state[\"task\"]),\n",
    "    ])\n",
    "    content = state.get('content', [])\n",
    "    for q in queries.queries:\n",
    "        response = tavily.search(q, max_results=3)\n",
    "        for result in response['results']:\n",
    "            content.append(result['content'])\n",
    "    return {\"content\": content}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_node(state:AgentState):\n",
    "    content = \"\\n\\n\".join(state['content'] or [])\n",
    "    user_message = HumanMessage(content = f\"{state['task']}\\n\\nHere is my plan:\\n\\n{state['plan']}\")\n",
    "    messages = [\n",
    "        SystemMessage(\n",
    "            content=WRITER_PROMPT.format(content=content)\n",
    "        ),\n",
    "        user_message\n",
    "    ]\n",
    "    resoponse = model.invoke(messages)\n",
    "    return {\n",
    "        \"draft\": resoponse.content, \n",
    "        \"revision_number\": state.get(\"revision_number\", 1) + 1\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reflection_node(state: AgentState):\n",
    "    messages = [\n",
    "        SystemMessage(content=REFLECTION_PROMPT),\n",
    "        HumanMessage(content=state[\"draft\"]),\n",
    "    ]\n",
    "    response = model.invoke(messages)\n",
    "    return {\"critique\": response.content}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def research_critique_node(state: AgentState):\n",
    "    queries = model.with_structured_output(Queries).invoke([\n",
    "        SystemMessage(content=RESEARCH_CRITIQUE_PROMPT),\n",
    "        HumanMessage(content=state[\"critique\"]),\n",
    "    ])\n",
    "    content = state.get('content', [])\n",
    "    for q in queries.queries:\n",
    "        response = tavily.search(q, max_results=3)\n",
    "        for result in response['results']:\n",
    "            content.append(result['content'])\n",
    "    return {\"content\": content}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def should_continue(state):\n",
    "    if state['revision_number'] >= state['max_revision']:\n",
    "        return END\n",
    "    return \"reflect\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_agent():\n",
    "    builder= StateGraph(AgentState)\n",
    "    inmem1 = InMemorySaver()\n",
    "    builder.add_node(\"planner\", plan_node)\n",
    "    builder.add_node(\"research_plan\", research_plan_node)\n",
    "    builder.add_node(\"generate\", generate_node)\n",
    "    builder.add_node(\"reflect\", reflection_node)\n",
    "    builder.add_node(\"research_critique\", research_critique_node)\n",
    "    \n",
    "    \n",
    "    builder.set_entry_point(\"planner\")\n",
    "\n",
    "    builder.add_conditional_edges(\n",
    "        \"generate\",\n",
    "        should_continue,\n",
    "        {END:END, \"reflect\": \"reflect\"}\n",
    "    )\n",
    "    builder.add_edge(\"planner\", \"research_plan\")\n",
    "    builder.add_edge(\"research_plan\", \"generate\")\n",
    "    \n",
    "    builder.add_edge(\"reflect\",  \"research_critique\")\n",
    "    builder.add_edge(\"research_critique\", \"generate\")\n",
    "\n",
    "    agent = builder.compile(checkpointer=inmem1)\n",
    "\n",
    "\n",
    "\n",
    "    return agent\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_agent()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping1 = {\n",
    "    'planner': 'plan',\n",
    "    'research_plan': 'content',\n",
    "    'generate': 'draft',\n",
    "    'reflect': 'critique',\n",
    "    'research_critique':'content'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_essay_on_topic(topic: str, intermediate:bool=False):\n",
    "    agent = create_agent()\n",
    "    intermediates = {}\n",
    "    thread1 = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "    console = Console()\n",
    "    console.print(Markdown(f'# Essay Topic: {topic}'))\n",
    "    for s in agent.stream({\n",
    "        \"task\": topic,\n",
    "        \"max_revision\": 3,\n",
    "        \"revision_number\": 1,\n",
    "    }, thread1):\n",
    "        node_name = list(s.keys())[0]\n",
    "        node_content = s[node_name][mapping1.get(node_name)]\n",
    "        console.print(Markdown(f'## {node_name.title()}'))\n",
    "        console.print(Markdown('---'))\n",
    "        if isinstance(node_content, str):\n",
    "            console.print(Markdown(node_content))\n",
    "        elif isinstance(node_content, list):\n",
    "            for i, p_ in enumerate(node_content):\n",
    "                console.print(Markdown(f\"{i}. {p_}\"))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter('ignore')\n",
    "    write_essay_on_topic('Write an Essay about HSBC, its origin, business and the current scenario')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
